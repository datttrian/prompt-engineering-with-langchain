{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":38501,"status":"ok","timestamp":1706651465739,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"sk4lfY0zCsa5","metadata":{}},"outputs":[],"source":["%%capture\n","!pip install langchain==0.1.4 openai==1.10.0 langchain-openai"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5896,"status":"ok","timestamp":1706651471628,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"_moU87efUosB","metadata":{},"outputId":"65d2f66b-7b5a-4bf1-da2e-5f80c9073e3c"},"outputs":[],"source":["import os\n","import getpass\n","\n","os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter Your OpenAI API Key:\")"]},{"cell_type":"markdown","metadata":{"id":"0ed8MD_LUp6I"},"source":["# Prompt Pipelining Overview\n","\n","\n","- üß± **Modularity**: Mix and match prompt pieces like LEGO blocks.\n","- üëì **Readability**: Break down complex prompts into easy bits.\n","- üß†**Flexibility**: Craft prompts on-the-go with logic-based assembly.\n","- üîÑ **Efficiency**: Loop to append for scenarios like few-shot learning.\n","- üìù‚ú®**Hybrid Construction**: Combine fixed text with variable-filled templates for structure and spontaneity.\n","- üí¨ **Chat-Friendly**: Create conversational prompts by stacking messages.\n","- üõ†Ô∏è **Customizability**: Let users build prompts with their own components.\n","\n","**String Prompt Pipelining:**\n","\n","- üîó **Sequential Flow**: Link templates or strings in order, starting with a prompt.\n","\n","Prompt pipelining turns the art of prompt crafting into a modular, efficient process, perfect for those looking to streamline and enhance their prompt design. üí°\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":658,"status":"ok","timestamp":1706650564037,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"rXzIc8jCXiob","metadata":{},"outputId":"d08e4ff7-9f05-491a-d022-1354b8b74bec"},"outputs":[{"data":{"text/plain":["PromptTemplate(input_variables=['activity', 'destination'], template=\"I'm heading to {destination}. Recommend a great {activity} spot!\")"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["from langchain.prompts import PromptTemplate\n","\n","prompt = (\n","    PromptTemplate.from_template(\"I'm heading to {destination}. \")\n","    + \"Recommend a great {activity} spot!\")\n","\n","prompt"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1706650576335,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"z1wpoDv7l3Wg","metadata":{},"outputId":"44fe5ed5-3312-486a-a97b-7abb100cf8a0"},"outputs":[{"data":{"text/plain":["PromptTemplate(input_variables=['activity', 'destination'], template=\"I'm heading to {destination}. Recommend a great {activity} spot!\\n\\nAlso, any local delicacies I should try?\")"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["prompt = prompt + \"\\n\\nAlso, any local delicacies I should try?\"\n","prompt"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":119,"status":"ok","timestamp":1706650589689,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"uuD4e2OwTTYy","metadata":{},"outputId":"ef04e436-050f-4c27-9bcd-48d410c87781"},"outputs":[{"name":"stdout","output_type":"stream","text":["I'm heading to {destination}. Recommend a great {activity} spot!\n","\n","Also, any local delicacies I should try?\n"]}],"source":["print(prompt.template)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":118,"status":"ok","timestamp":1706650600158,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"XVbMS46yYIwO","metadata":{},"outputId":"296bbc94-2bf6-4354-f22e-5c1b4c342d7b"},"outputs":[{"data":{"text/plain":["\"I'm heading to Punjab. Recommend a great dining spot!\\n\\nAlso, any local delicacies I should try?\""]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["prompt.format(destination=\"Punjab\", activity=\"dining\")"]},{"cell_type":"markdown","metadata":{"id":"kCuU15Zsb6-E"},"source":["### The key differences between prompt pipelining and multi-input prompts are:\n","\n","üöÇ **Composition**: Pipelining links individual prompts into a cohesive journey.\n","\n","üñºÔ∏è **Independence**: Each pipeline component is crafted separately before integration.\n","\n","üö∂‚Äç‚ôÇÔ∏è **Sequence**: Pipelining lines up components, unlike multi-input prompts that handle inputs collectively.\n","\n","üìã **Reuse**: Pipelining excels in reusing pieces; multi-input prompts manage multiple data points in one go.\n","\n","üìñ **Outcome**: Pipelining produces a single narrative; multi-input prompts generate a combined result.\n","\n","üß± **Construction**: Pipelining is about assembling prompts step by step, while multi-input prompts are about managing various inputs at once.\n","\n","In short, pipelining is like creating a melody note by note, whereas multi-input prompts are like playing chords, hitting multiple notes simultaneously.\n"]},{"cell_type":"markdown","metadata":{"id":"vWKXtrGIYPjX"},"source":["# Use in a chain"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":1256,"status":"ok","timestamp":1706650704561,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"sgGCg2s8YtqN","metadata":{}},"outputs":[],"source":["from langchain_openai import ChatOpenAI\n","from langchain_core.output_parsers import StrOutputParser"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3820,"status":"ok","timestamp":1706650733759,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"F8-qiXIAYu7Q","metadata":{},"outputId":"16ee8e5e-76e9-490a-94c2-b334dca8ca01"},"outputs":[{"name":"stdout","output_type":"stream","text":["One of the popular dining spots in Punjab is \"Sarson Da Saag and Makki Di Roti\" which is known for its traditional Punjabi cuisine. Another great option is \"Kesar Da Dhaba\" known for its delicious vegetarian dishes.\n","\n","When in Punjab, you must try the local delicacies such as Butter Chicken, Tandoori Chicken, Amritsari Fish, Chole Bhature, and Lassi. These dishes are a must-try for anyone visiting Punjab."]}],"source":["llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.75)\n","\n","output_parser = StrOutputParser()\n","\n","chain = prompt | llm | output_parser\n","\n","for chunk in chain.stream({\"destination\":\"Punjab\", \"activity\":\"dining\"}):\n","  print(chunk, end=\"\", flush=True)"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":101,"status":"ok","timestamp":1706650753205,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"X7COZydQl2gz","metadata":{}},"outputs":[],"source":["prompt = prompt + \" How should I greet the locals in a jolly, informal manner?\"\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":106,"status":"ok","timestamp":1706650761065,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"Vl0vMx1WT7_n","metadata":{},"outputId":"4b201fa4-ac38-425b-9ba2-51fbf72dc5f6"},"outputs":[{"data":{"text/plain":["\"I'm heading to {destination}. Recommend a great {activity} spot!\\n\\nAlso, any local delicacies I should try? How should I greet the locals in a jolly, informal manner?\""]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["prompt.template"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1897,"status":"ok","timestamp":1706650769170,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"oZ-yI33JT7g8","metadata":{},"outputId":"daeae057-1639-408c-a40f-9c97fc017159"},"outputs":[{"name":"stdout","output_type":"stream","text":["One great dining spot in Punjab is the famous Kesar Da Dhaba in Amritsar, known for its delicious Punjabi cuisine and traditional ambiance. \n","\n","Some local delicacies you should try include sarson da saag and makki di roti, chole bhature, butter chicken, and lassi.\n","\n","To greet the locals in a jolly, informal manner, you can use \"Sat Sri Akal\" or \"Sasriakal\", which is a common Punjabi greeting. It translates to \"may you have a long life\" and is often used to say hello."]}],"source":["chain = prompt | llm | output_parser\n","\n","for chunk in chain.stream({\"destination\":\"Punjab\", \"activity\":\"dining\"}):\n","  print(chunk, end=\"\", flush=True)"]},{"cell_type":"markdown","metadata":{"id":"V4WgevnuoYIO"},"source":["# Example usecase"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1708,"status":"ok","timestamp":1706650815100,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"_BdVa1z2l2X0","metadata":{},"outputId":"fa954046-c2b8-446b-f689-f0df128b29a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sure! One highly recommended dining spot in Punjab is Barbeque Nation. They offer a wide variety of delicious barbeque dishes and a great ambiance for a memorable dining experience. Another popular option is Kesar da Dhaba, known for its authentic Punjabi cuisine and traditional atmosphere. Both of these restaurants are sure to provide a fantastic dining experience during your visit to Punjab."]}],"source":["class TravelChatbot:\n","    def __init__(self, base_template):\n","        self.model = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.75)\n","        self.base_prompt = PromptTemplate.from_template(base_template)\n","\n","    def append_to_prompt(self, additional_text):\n","        self.base_prompt += additional_text\n","\n","    def run_chain(self, destination, activity):\n","        output_parser = StrOutputParser()\n","        chain = self.base_prompt | self.model | output_parser\n","        for chunk in chain.stream({\"destination\":destination, \"activity\":activity}):\n","          print(chunk, end=\"\", flush=True)\n","\n","# Usage\n","base_template = \"I'm heading to {destination}. Recommend a great {activity} spot!\"\n","\n","chatbot = TravelChatbot(base_template)\n","\n","# Basic prompt\n","chatbot.run_chain(destination=\"Punjab\", activity=\"dining\")"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2110,"status":"ok","timestamp":1706650820770,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"9PvagxTLl2PF","metadata":{},"outputId":"9c42b084-3667-4cc0-df5a-2ca65eff9a1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["One of the best dining spots in Punjab is Bukhara Grill, known for its delicious tandoori dishes and traditional Punjabi cuisine. Another popular choice is Kesar da Dhaba, where you can savor authentic Punjabi flavors in a rustic setting.\n","\n","As for local delicacies, be sure to try the famous Amritsari Kulcha, a type of Indian bread stuffed with spiced potatoes and served with chole (chickpea curry). Also, don't miss out on the rich and creamy Sarson da Saag (mustard greens curry) served with Makki di Roti (corn bread). And of course, indulge in some delicious Punjabi sweets like Gulab Jamun and Jalebi. Enjoy your culinary adventure in Punjab!"]}],"source":["# Append more to the prompt and run again\n","chatbot.append_to_prompt(\"\\n\\nAlso, any local delicacies I should try?\")\n","\n","chatbot.run_chain(destination=\"Punjab\", activity=\"dining\")"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4936,"status":"ok","timestamp":1706650827807,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"ufMFRyBnltpk","metadata":{},"outputId":"1ca7df13-5751-455e-9fad-c572346bd051"},"outputs":[{"name":"stdout","output_type":"stream","text":["One great dining spot in Punjab is Makhan Fish & Chicken Corner in Amritsar, known for its delicious Punjabi cuisine and famous fish and chicken dishes.\n","\n","Some local delicacies you should try include butter chicken, tandoori chicken, saag and makki di roti, chole bhature, and lassi.\n","\n","To greet the locals in a friendly, informal, jolly colloquial manner, you can say \"Sat Sri Akal\" or \"Sasriakal\" which means \"Hello\" in Punjabi. It's sure to bring a smile to their faces!"]}],"source":["chatbot.append_to_prompt(\" How should I greet the locals in a friendly, informal, jolly colloquial manner?\")\n","\n","chatbot.run_chain(destination=\"Punjab\", activity=\"dining\")"]},{"cell_type":"markdown","metadata":{"id":"3ySTTr9VYx1f"},"source":["# Chat Prompt Pipeline\n","\n","üß© **Composition**: Chat prompt pipelining turns reusable message blocks into a complete conversation flow.\n","\n","üõ†Ô∏è **Versatility**: Mix and match static messages with dynamic templates for a custom dialogue.\n","\n","üîó **End Result**: You get a ChatPromptTemplate that's ready for action, crafted from your message lineup.\n","\n","üèóÔ∏è **Modularity**: Like using building blocks, this method lets you construct prompts piece by piece for maximum flexibility.\n","\n","In essence, chat prompt pipelining is about assembling conversations from logical blocks, creating a user-friendly and adaptable ChatPromptTemplate.\n"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1997,"status":"ok","timestamp":1706651506640,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"RK4T0u4Io4S6","metadata":{},"outputId":"5393a23b-a1e2-41cc-d2f1-850564af967e"},"outputs":[{"name":"stdout","output_type":"stream","text":["input_variables=['input'] messages=[SystemMessage(content='Welcome to the East End Cockney Chat! üá¨üáß'), HumanMessage(content=\"Alright, guv'nor?\"), AIMessage(content='Not too shabby. Did you hear about the London fog?'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))]\n"]}],"source":["from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n","from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_openai import ChatOpenAI\n","\n","# Setting the scene with a Cockney-themed system message\n","prompt = SystemMessage(content=\"Welcome to the East End Cockney Chat! üá¨üáß\")\n","\n","# Constructing a chat flow with dry humour\n","new_prompt = (\n","    prompt\n","    + HumanMessage(content=\"Alright, guv'nor?\")\n","    + AIMessage(content=\"Not too shabby. Did you hear about the London fog?\")\n","    + \"{input}\"\n",")\n","\n","# Formatting the chat with the user's response\n","new_prompt.format_messages(input=\"No, what about it?\")\n","\n","print(new_prompt)\n"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":150,"status":"ok","timestamp":1706651525801,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"MN3bSfpbWbca","metadata":{},"outputId":"46e75993-e29a-410c-84d1-76eb4dfcde7e"},"outputs":[{"data":{"text/plain":["[SystemMessage(content='Welcome to the East End Cockney Chat! üá¨üáß'),\n"," HumanMessage(content=\"Alright, guv'nor?\"),\n"," AIMessage(content='Not too shabby. Did you hear about the London fog?'),\n"," HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))]"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["new_prompt.messages"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2401,"status":"ok","timestamp":1706651544674,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"XDeZGAErWbis","metadata":{},"outputId":"2c3a45e1-7b43-44fa-a817-f75e2a2572b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["It was pea souper, mate! Couldn't see me hand in front of me face!"]}],"source":["model = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.75)\n","\n","output_parser = StrOutputParser()\n","\n","chain = new_prompt | model | output_parser\n","\n","# Running the chatbot to get the punchline\n","for chunk in chain.stream({\"input\":\"No, what about it?\"}):\n","  print(chunk, end=\"\", flush=True)"]},{"cell_type":"markdown","metadata":{"id":"rl5mldDcqzOp"},"source":["# Prompt Composition\n","\n","\n","üß¨ **Prompt Composition**: Reuse prompt segments with ease using the PipelinePrompt feature.\n","\n","üèÅ **1. Final Prompt**: The end product that you present to the model.\n","\n","üîó **2. Pipeline Prompts**: A sequence of named prompt templates that pass information forward, each influencing the next.\n","\n","To summarize, PipelinePrompt allows for the efficient building of complex prompts by reusing and chaining together smaller, named components.\n"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":158,"status":"ok","timestamp":1706651886128,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"328V_Y-Qq1UH","metadata":{}},"outputs":[],"source":["from langchain.prompts.pipeline import PipelinePromptTemplate\n","from langchain.prompts.prompt import PromptTemplate"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":163,"status":"ok","timestamp":1706651901343,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"4IUN1EfirhVR","metadata":{}},"outputs":[],"source":["full_template = \"\"\"{introduction}\n","\n","{example}\n","\n","{start}\"\"\"\n","\n","full_prompt = PromptTemplate.from_template(full_template)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1706651916255,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"GNgI2_fvYWpG","metadata":{},"outputId":"328ff78d-8065-4db1-d7ab-4d42e7a58b53"},"outputs":[{"data":{"text/plain":["['example', 'introduction', 'start']"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["full_prompt.input_variables"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":166,"status":"ok","timestamp":1706651930850,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"j2w6SdMmnXDU","metadata":{}},"outputs":[],"source":["introduction_template = \"\"\"You are impersonating {person}.\"\"\"\n","\n","introduction_prompt = PromptTemplate.from_template(introduction_template)"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":182,"status":"ok","timestamp":1706651955698,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"8hzB8AIfYdvo","metadata":{},"outputId":"311585f4-0824-4103-a4d7-b812f3ae90cb"},"outputs":[{"data":{"text/plain":["['person']"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["introduction_prompt.input_variables"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":163,"status":"ok","timestamp":1706651968447,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"3JbuG8wEnYe9","metadata":{}},"outputs":[],"source":["example_template = \"\"\"Here's an example of an interaction:\n","\n","Q: {example_q}\n","A: {example_a}\"\"\"\n","\n","example_prompt = PromptTemplate.from_template(example_template)"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":378,"status":"ok","timestamp":1706651989875,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"pHAMVyaGnZ9J","metadata":{}},"outputs":[],"source":["start_template = \"\"\"Now, do this for real!\n","\n","Q: {input}\n","A:\"\"\"\n","\n","start_prompt = PromptTemplate.from_template(start_template)"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":170,"status":"ok","timestamp":1706652035558,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"fqtrUTH9Ytac","metadata":{},"outputId":"41fbe8fd-fbc3-4290-d011-80fe2fe76519"},"outputs":[{"data":{"text/plain":["PromptTemplate(input_variables=['example', 'introduction', 'start'], template='{introduction}\\n\\n{example}\\n\\n{start}')"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["full_prompt"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":146,"status":"ok","timestamp":1706652061093,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"Drwq7Z4cnbN7","metadata":{}},"outputs":[],"source":["input_prompts = [\n","    (\"introduction\", introduction_prompt),\n","    (\"example\", example_prompt),\n","    (\"start\", start_prompt)\n","]\n","pipeline_prompt = PipelinePromptTemplate(final_prompt=full_prompt, pipeline_prompts=input_prompts)"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":153,"status":"ok","timestamp":1706652091268,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"WYgcG7BAncnT","metadata":{},"outputId":"0258f251-6e89-4a14-a0a4-cf112cd9c0ba"},"outputs":[{"data":{"text/plain":["['example_a', 'example_q', 'person', 'input']"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["pipeline_prompt.input_variables"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":145,"status":"ok","timestamp":1706652115425,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"lsNGuKCXnhpz","metadata":{},"outputId":"bea196ba-86cd-4eac-a166-540a685941ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["You are impersonating Elon Musk.\n","\n","Here's an example of an interaction:\n","\n","Q: What's your favorite car?\n","A: Tesla\n","\n","Now, do this for real!\n","\n","Q: What's your favorite social media site?\n","A:\n"]}],"source":["last_prompt = pipeline_prompt.format(\n","    person=\"Elon Musk\",\n","    example_q=\"What's your favorite car?\",\n","    example_a=\"Tesla\",\n","    input=\"What's your favorite social media site?\"\n",")\n","\n","print(last_prompt)"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":5509,"status":"ok","timestamp":1706652782306,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"ahbbsNgSoUtw","metadata":{},"outputId":"7f7a3c21-3a37-4c8d-9aa1-3e7c520416ee"},"outputs":[{"data":{"text/plain":["'Twitter, because it allows me to directly communicate with my followers and share updates and news about my companies and projects. Plus, the character limit forces me to be concise and to the point.'"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["from langchain_openai import ChatOpenAI\n","\n","llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.75)\n","\n","chain = pipeline_prompt | llm | StrOutputParser()\n","\n","chain.invoke({\n","    \"person\":\"Elon Musk\",\"example_q\":\"What's your favorite car?\",\n","    \"example_a\":\"Tesla\",\n","    \"input\":\"What's your favorite social media site and why?\"\n","    })"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":239,"status":"ok","timestamp":1706652819639,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"dFIiHk-FnjVu","metadata":{}},"outputs":[],"source":["from langchain.prompts import PromptTemplate, PipelinePromptTemplate\n","\n","class CookingShowChatbot:\n","    def __init__(self):\n","        # Base template for the cooking show scenario\n","        self.full_template = \"\"\"\n","        {introduction}\n","\n","        {example_dish}\n","\n","        {present_dish}\"\"\"\n","        self.full_prompt = PromptTemplate.from_template(self.full_template)\n","\n","        # Introduction where the user impersonates a famous chef\n","        self.introduction_template = \"\"\"Welcome to the cooking show! Today, you're channeling the spirit of Chef {chef_name}.\"\"\"\n","        self.introduction_prompt = PromptTemplate.from_template(self.introduction_template)\n","\n","        # Example dish made by the famous chef\n","        self.example_dish_template = \"\"\"Remember when Chef {chef_name} made that delicious {example_dish_name}? It was a hit!\"\"\"\n","        self.example_dish_prompt = PromptTemplate.from_template(self.example_dish_template)\n","\n","        # User's turn to present their dish\n","        self.present_dish_template = \"\"\"Now, it's your turn! Show us how you make your {user_dish_name}. Let's get cooking!\"\"\"\n","        self.present_dish_prompt = PromptTemplate.from_template(self.present_dish_template)\n","\n","        # Combining the prompts into a pipeline\n","        self.input_prompts = [\n","            (\"introduction\", self.introduction_prompt),\n","            (\"example_dish\", self.example_dish_prompt),\n","            (\"present_dish\", self.present_dish_prompt)\n","        ]\n","        self.pipeline_prompt = PipelinePromptTemplate(final_prompt=self.full_prompt,\n","                                                      pipeline_prompts=self.input_prompts\n","                                                      )\n","\n","    def run_scenario(self, chef_name, example_dish_name, user_dish_name):\n","        chain = self.pipeline_prompt | llm | StrOutputParser()\n","\n","        response = chain.invoke({\"chef_name\":chef_name, \"example_dish_name\":example_dish_name, \"user_dish_name\":user_dish_name})\n","\n","        return response\n","\n","\n"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7355,"status":"ok","timestamp":1706652827140,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"CjGCHwc1oRz9","metadata":{},"outputId":"d8711098-12d9-4fc5-f7f4-5133a7dcbaca"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","Alright, let's get started on this vegan lasagna. First, preheat the oven to 375¬∞F (190¬∞C). \n","\n","Next, we'll need some lasagna noodles, marinara sauce, tofu ricotta, spinach, mushrooms, and vegan mozzarella cheese.\n","\n","Start by cooking the lasagna noodles according to the package instructions. While that's cooking, saut√© the mushrooms and spinach in a pan with a little olive oil until they're softened.\n","\n","Now, it's time to assemble the lasagna. Start by spreading a layer of marinara sauce on the bottom of a baking dish. Then add a layer of the cooked lasagna noodles, followed by a layer of the tofu ricotta, saut√©ed mushrooms and spinach, and a sprinkle of vegan mozzarella cheese. Repeat these layers until you've used up all your ingredients, finishing with a layer of marinara sauce and vegan mozzarella cheese on top.\n","\n","Cover the dish with foil and bake in the preheated oven for 30 minutes. Then, remove the foil and bake for an additional 15 minutes, or until the cheese is melted and bubbly.\n","\n","Once it's done, let the lasagna cool for a few minutes before slicing and serving. And there you have it, a delicious and hearty vegan lasagna, sure to impress even Chef Gordon Ramsay! Enjoy!\n"]}],"source":["chatbot = CookingShowChatbot()\n","scenario = chatbot.run_scenario(chef_name=\"Gordon Ramsay\", example_dish_name=\"Beef Wellington\", user_dish_name=\"Vegan Lasagna\")\n","print(scenario)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOptEzKiPqIm37Zr+QgaVdl","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
