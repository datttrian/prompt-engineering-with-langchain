{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSTvB1kEo_kB",
        "outputId": "de45174d-c2ea-44d1-969b-c3f28f9aec8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API Key:··········\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LINkd-FXo_bk",
        "outputId": "da76af4b-89f9-4469-e8d2-0e529e90d324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your LangSmith API key: ··········\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass('Enter your LangSmith API key: ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bSVcYzlro8zN"
      },
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "unique_id = uuid4().hex[0:8]\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Managing_Agent_Prompt_Size_{unique_id}\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKBSDIiRCKRP",
        "outputId": "8aab321b-a9b0-45a3-b977-6e279e9e076a"
      },
      "outputs": [],
      "source": [
        "pip install langchain langchain-openai langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GhGrsq6Tp3KH"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain.agents import AgentExecutor, load_tools\n",
        "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
        "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
        "from langchain_community.tools import WikipediaQueryRun, DuckDuckGoSearchRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper, DuckDuckGoSearchAPIWrapper\n",
        "from langchain_core.prompt_values import ChatPromptValue\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_openai import ChatOpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfdoCUbbo85r"
      },
      "source": [
        "# Managing Prompt Length\n",
        "\n",
        "- Agents dynamically use tools to gather information, adding the results to their prompts.\n",
        "\n",
        "- This can lead to large prompts that exceed the model's context window.\n",
        "\n",
        "- LCEL allows for custom functions to manage prompt size within an agent.\n",
        "\n",
        "- Example: An agent that searches Wikipedia for information.\n",
        "\n",
        "- It's important to trim the prompt by keeping only necessary information and removing the rest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lANXUGczCV8r",
        "outputId": "019d9e73-a3ff-4866-dffd-0d487f623f65"
      },
      "outputs": [],
      "source": [
        "pip install wikipedia duckduckgo-search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "b8jQaP70qKOI"
      },
      "outputs": [],
      "source": [
        "wiki = WikipediaQueryRun(\n",
        "    api_wrapper=WikipediaAPIWrapper(top_k_results=10, doc_content_chars_max=10_000)\n",
        ")\n",
        "\n",
        "ddg_search = search = DuckDuckGoSearchRun(\n",
        "    api_wrapper=DuckDuckGoSearchAPIWrapper(region=\"us-en\", time=\"d\", max_results=5)\n",
        ")\n",
        "\n",
        "tools = [ddg_search, wiki ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JJTu-6PVqKbS"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"\"\"You are the world's greatest research assistant. You know exactly\n",
        "        where and what to search for given a query. You've been a research assistant to\n",
        "        people like Yann LeCun, Geoffry Hinton, and Francois Chollet.\"\"\"),\n",
        "        (\"user\", \"{input}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Cbbu9HKwqeHs"
      },
      "outputs": [],
      "source": [
        "agent = (\n",
        "    {\n",
        "        \"input\": itemgetter(\"input\"),\n",
        "        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
        "            x[\"intermediate_steps\"]\n",
        "        ),\n",
        "    }\n",
        "    | prompt\n",
        "    | llm.bind_functions(tools)\n",
        "    | OpenAIFunctionsAgentOutputParser()\n",
        ")\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxNU4Ar3KAsp",
        "outputId": "8b430bad-ed37-4fcf-eeaa-4d007e2b0533"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mDeep learning works due to a combination of factors, including the architecture of the model, the data it is trained on, and the optimization algorithms used during training. Here are some key points to consider:\n",
            "\n",
            "1. **Architecture of the Model**: Deep learning models, particularly neural networks, are capable of learning complex patterns and representations from data due to their hierarchical structure. Each layer in a neural network extracts features at different levels of abstraction, allowing the model to learn intricate patterns in the data.\n",
            "\n",
            "2. **Data**: The quality and quantity of data used to train a deep learning model play a crucial role in its performance. Deep learning models require large amounts of labeled data to generalize well and make accurate predictions. The diversity and representativeness of the data also impact the model's ability to learn meaningful patterns.\n",
            "\n",
            "3. **Optimization Algorithms**: Deep learning models are trained using optimization algorithms such as gradient descent, which update the model's parameters to minimize a loss function. These algorithms iteratively adjust the model's weights to improve its performance on the training data.\n",
            "\n",
            "4. **Theoretical Support**: The universal approximation theorem states that a feedforward neural network with a single hidden layer containing a finite number of neurons can approximate any continuous function to a desired degree of accuracy. This theorem provides theoretical support for the effectiveness of neural networks in learning complex functions.\n",
            "\n",
            "5. **Human Data Generation**: Humans generate data through their interactions with the environment, leading to rich and diverse datasets that capture complex patterns and relationships. This diverse data is essential for training deep learning models to generalize well across different tasks.\n",
            "\n",
            "6. **Philosophical Implications**: The success of deep learning raises questions about the nature of intelligence, learning, and cognition. The ability of neural networks to learn from data and make autonomous decisions challenges traditional notions of human cognition and raises philosophical questions about the nature of intelligence.\n",
            "\n",
            "7. **Future Perspectives**: In the future, people may talk about deep learning as a transformative technology that revolutionized various industries, including healthcare, finance, and autonomous systems. Deep learning is likely to be viewed as a powerful tool for solving complex problems and making sense of large amounts of data.\n",
            "\n",
            "Overall, the combination of model architecture, data, optimization algorithms, theoretical support, human data generation, and philosophical implications contributes to the success and effectiveness of deep learning.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': \"Why does deep learning work? Is there some inherent property\\n        of a model's architecture that makes it capable of learning? Or is it more\\n        about the data it is trained on?  Are there any theorems or hypothesis that you can find that\\n        support this? Is there something special about how humans generate data?\\n        What philosophical implications does this have about why deep learning works.\\n        How will people in the future talk about what deep learning is?\",\n",
              " 'output': \"Deep learning works due to a combination of factors, including the architecture of the model, the data it is trained on, and the optimization algorithms used during training. Here are some key points to consider:\\n\\n1. **Architecture of the Model**: Deep learning models, particularly neural networks, are capable of learning complex patterns and representations from data due to their hierarchical structure. Each layer in a neural network extracts features at different levels of abstraction, allowing the model to learn intricate patterns in the data.\\n\\n2. **Data**: The quality and quantity of data used to train a deep learning model play a crucial role in its performance. Deep learning models require large amounts of labeled data to generalize well and make accurate predictions. The diversity and representativeness of the data also impact the model's ability to learn meaningful patterns.\\n\\n3. **Optimization Algorithms**: Deep learning models are trained using optimization algorithms such as gradient descent, which update the model's parameters to minimize a loss function. These algorithms iteratively adjust the model's weights to improve its performance on the training data.\\n\\n4. **Theoretical Support**: The universal approximation theorem states that a feedforward neural network with a single hidden layer containing a finite number of neurons can approximate any continuous function to a desired degree of accuracy. This theorem provides theoretical support for the effectiveness of neural networks in learning complex functions.\\n\\n5. **Human Data Generation**: Humans generate data through their interactions with the environment, leading to rich and diverse datasets that capture complex patterns and relationships. This diverse data is essential for training deep learning models to generalize well across different tasks.\\n\\n6. **Philosophical Implications**: The success of deep learning raises questions about the nature of intelligence, learning, and cognition. The ability of neural networks to learn from data and make autonomous decisions challenges traditional notions of human cognition and raises philosophical questions about the nature of intelligence.\\n\\n7. **Future Perspectives**: In the future, people may talk about deep learning as a transformative technology that revolutionized various industries, including healthcare, finance, and autonomous systems. Deep learning is likely to be viewed as a powerful tool for solving complex problems and making sense of large amounts of data.\\n\\nOverall, the combination of model architecture, data, optimization algorithms, theoretical support, human data generation, and philosophical implications contributes to the success and effectiveness of deep learning.\"}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"\"\"Why does deep learning work? Is there some inherent property\n",
        "        of a model's architecture that makes it capable of learning? Or is it more\n",
        "        about the data it is trained on?  Are there any theorems or hypothesis that you can find that\n",
        "        support this? Is there something special about how humans generate data?\n",
        "        What philosophical implications does this have about why deep learning works.\n",
        "        How will people in the future talk about what deep learning is?\"\"\"\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzEE-UFMsHRw"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "carhzm57qpGz"
      },
      "outputs": [],
      "source": [
        "def condense_prompt(prompt: ChatPromptValue, max_tokens: int = 4_000) -> ChatPromptValue:\n",
        "    \"\"\"\n",
        "    Condenses the input prompt to ensure the total number of tokens does not exceed a specified limit.\n",
        "\n",
        "    This function processes a ChatPromptValue object's messages to reduce the total token count to\n",
        "    within a specified limit. It progressively removes messages from the beginning of the AI function-related\n",
        "    messages until the total token count is under the specified limit, while always preserving the first\n",
        "    two messages for essential context or instructions.\n",
        "\n",
        "    Parameters:\n",
        "    - prompt (ChatPromptValue): The input ChatPromptValue object containing a sequence of messages.\n",
        "    - max_tokens (int, optional): The maximum number of tokens allowed for the condensed prompt. Defaults to 4,000.\n",
        "\n",
        "    Returns:\n",
        "    - ChatPromptValue: A new ChatPromptValue object with the condensed sequence of messages, ensuring\n",
        "      the total token count is within the specified limit.\n",
        "\n",
        "    Note:\n",
        "    - This function is useful for scenarios where the prompt for an AI model exceeds the maximum token limit,\n",
        "      allowing for the inclusion of necessary context while staying within token constraints.\n",
        "    \"\"\"\n",
        "    messages = prompt.to_messages()\n",
        "    num_tokens = llm.get_num_tokens_from_messages(messages)\n",
        "    ai_function_messages = messages[2:]\n",
        "\n",
        "    while num_tokens > max_tokens:\n",
        "        ai_function_messages = ai_function_messages[2:]\n",
        "        num_tokens = llm.get_num_tokens_from_messages(\n",
        "            messages[:2] + ai_function_messages\n",
        "        )\n",
        "\n",
        "    messages = messages[:2] + ai_function_messages\n",
        "    return ChatPromptValue(messages=messages)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERs7mNdFraSt",
        "outputId": "8afc81e5-35c5-4ac2-9f06-84c8bcfbdee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mDeep learning works due to a combination of factors, including the architecture of the model, the data it is trained on, and the optimization process. Here are some insights into the questions you posed:\n",
            "\n",
            "1. **Architecture of the Model**: The architecture of a deep learning model, such as neural networks with multiple layers, enables it to learn complex patterns and representations from the data. The hierarchical structure of deep learning models allows them to capture intricate relationships in the data, making them powerful for tasks like image recognition, natural language processing, and more.\n",
            "\n",
            "2. **Data it is Trained On**: The quality and quantity of data used to train a deep learning model play a crucial role in its performance. Deep learning models require large amounts of labeled data to generalize well and make accurate predictions. The diversity and richness of the training data contribute to the model's ability to learn meaningful features.\n",
            "\n",
            "3. **Theoretical Support**: There are theoretical results, such as the Universal Approximation Theorem, which states that a neural network with a single hidden layer can approximate any continuous function. This theorem provides a foundational understanding of the representational power of neural networks and their capacity to learn complex functions.\n",
            "\n",
            "4. **Human Data Generation**: Humans generate data through their interactions with the environment, leading to rich and diverse datasets that capture a wide range of patterns and concepts. This diversity in human-generated data contributes to the success of deep learning models in learning from various sources of information.\n",
            "\n",
            "5. **Philosophical Implications**: The success of deep learning raises philosophical questions about the nature of intelligence, learning, and cognition. It challenges traditional notions of human cognition and perception by demonstrating that machines can learn and make decisions based on data-driven algorithms.\n",
            "\n",
            "6. **Future Perspectives**: In the future, people may talk about deep learning as a revolutionary technology that transformed various industries and fields. It may be viewed as a key driver of artificial intelligence advancements, enabling machines to perform tasks that were once thought to be exclusive to human intelligence.\n",
            "\n",
            "If you would like more in-depth information or specific references to support these points, feel free to let me know!\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': \"Why does deep learning work? Is there some inherent property\\n        of a model's architecture that makes it capable of learning? Or is it more\\n        about the data it is trained on?  Are there any theorems or hypothesis that you can find that\\n        support this? Is there something special about how humans generate data?\\n        What philosophical implications does this have about why deep learning works.\\n        How will people in the future talk about what deep learning is?\",\n",
              " 'output': \"Deep learning works due to a combination of factors, including the architecture of the model, the data it is trained on, and the optimization process. Here are some insights into the questions you posed:\\n\\n1. **Architecture of the Model**: The architecture of a deep learning model, such as neural networks with multiple layers, enables it to learn complex patterns and representations from the data. The hierarchical structure of deep learning models allows them to capture intricate relationships in the data, making them powerful for tasks like image recognition, natural language processing, and more.\\n\\n2. **Data it is Trained On**: The quality and quantity of data used to train a deep learning model play a crucial role in its performance. Deep learning models require large amounts of labeled data to generalize well and make accurate predictions. The diversity and richness of the training data contribute to the model's ability to learn meaningful features.\\n\\n3. **Theoretical Support**: There are theoretical results, such as the Universal Approximation Theorem, which states that a neural network with a single hidden layer can approximate any continuous function. This theorem provides a foundational understanding of the representational power of neural networks and their capacity to learn complex functions.\\n\\n4. **Human Data Generation**: Humans generate data through their interactions with the environment, leading to rich and diverse datasets that capture a wide range of patterns and concepts. This diversity in human-generated data contributes to the success of deep learning models in learning from various sources of information.\\n\\n5. **Philosophical Implications**: The success of deep learning raises philosophical questions about the nature of intelligence, learning, and cognition. It challenges traditional notions of human cognition and perception by demonstrating that machines can learn and make decisions based on data-driven algorithms.\\n\\n6. **Future Perspectives**: In the future, people may talk about deep learning as a revolutionary technology that transformed various industries and fields. It may be viewed as a key driver of artificial intelligence advancements, enabling machines to perform tasks that were once thought to be exclusive to human intelligence.\\n\\nIf you would like more in-depth information or specific references to support these points, feel free to let me know!\"}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent = (\n",
        "    {\n",
        "        \"input\": itemgetter(\"input\"),\n",
        "        \"agent_scratchpad\": lambda x: format_to_openai_function_messages(\n",
        "            x[\"intermediate_steps\"]\n",
        "        ),\n",
        "    }\n",
        "    | prompt\n",
        "    | condense_prompt\n",
        "    | llm.bind_functions(tools)\n",
        "    | OpenAIFunctionsAgentOutputParser()\n",
        ")\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"\"\"Why does deep learning work? Is there some inherent property\n",
        "        of a model's architecture that makes it capable of learning? Or is it more\n",
        "        about the data it is trained on?  Are there any theorems or hypothesis that you can find that\n",
        "        support this? Is there something special about how humans generate data?\n",
        "        What philosophical implications does this have about why deep learning works.\n",
        "        How will people in the future talk about what deep learning is?\"\"\"\n",
        "    }\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
