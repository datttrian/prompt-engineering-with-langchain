{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":30593,"status":"ok","timestamp":1706643638604,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"QhbzFH3vVgy6"},"outputs":[],"source":["%%capture\n","!pip install langchain==0.1.4 openai==1.10.0 langchain-openai"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4532,"status":"ok","timestamp":1706643643133,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"_vWgLxI2V5qO","outputId":"fa361157-01a2-4ee9-df16-eb02b6e23b1d"},"outputs":[],"source":["import os\n","import getpass\n","\n","os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter Your OpenAI API Key:\")"]},{"cell_type":"markdown","metadata":{"id":"r8cH681iWAyu"},"source":["## Structure of a Prompt\n","\n","\n","üéØ **Prompt Structure Essentials:**\n","\n","1. üó∫Ô∏è **Instructions:** Guide the model on what to do.\n","2. üìö **External Info/Context:** Additional data or background to inform the response.\n","3. ‚ùì **User Query:** The direct question or input from you.\n","4. ‚ú® **Output Indicator:** Signals the start of the model's response.\n","\n","**Why Use a Prompt Template?**\n","\n","- üîÑ **Consistency:** Ensures uniform prompts.\n","- ‚è±Ô∏è **Efficiency:** Saves time with a ready-to-go format.\n","- üéØ **Accuracy:** Tailors the model's responses to be more on point.\n","\n","A prompt template is like a recipe, mixing user input (üë§) with a sprinkle of instructions (üìù), a dash of context (üí°), and an output indicator (üîÆ) to serve up the perfect response!\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":697,"status":"ok","timestamp":1706643826755,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"E7ttt5EFnpzQ"},"outputs":[],"source":["from langchain import PromptTemplate\n","\n","template = \"\"\"You are an expert in deep learning and PyTorch. You are ptrblck from the PyTorch Forums.\n","\n","You answer queries by being brief, bright, and concise.\n","\n","Query: {query}\n","\"\"\""]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":149,"status":"ok","timestamp":1706643853320,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"ONXASqFaKb6T","outputId":"3c31c145-0190-433b-a77c-5469fc6c9a6c"},"outputs":[{"name":"stdout","output_type":"stream","text":["You are an expert in deep learning and PyTorch. You are ptrblck from the PyTorch Forums.\n","\n","You answer queries by being brief, bright, and concise.\n","\n","Query: \u001b[33;1m\u001b[1;3m{query}\u001b[0m\n","\n"]}],"source":["# instantiate using the initializer\n","prompt_template = PromptTemplate(input_variables = ['query'],template = template)\n","prompt_template.pretty_print()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":147,"status":"ok","timestamp":1706643863420,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"WwaUaEFuoZZx","outputId":"696cd748-efa8-489a-992d-e28f9fb57a7e"},"outputs":[{"name":"stdout","output_type":"stream","text":["You are an expert in deep learning and PyTorch. You are ptrblck from the PyTorch Forums.\n","\n","You answer queries by being brief, bright, and concise.\n","\n","Query: Give me the outline of a PyTorch training loop.\n","\n"]}],"source":["print(prompt_template.format(query=\"Give me the outline of a PyTorch training loop.\"))"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":372,"status":"ok","timestamp":1706643892497,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"2rQmu1SsKyrn","outputId":"300a4e49-b91f-43ed-b482-fabc98f04015"},"outputs":[{"name":"stdout","output_type":"stream","text":["You are an expert in deep learning and PyTorch. You are ptrblck from the PyTorch Forums.\n","\n","You answer queries by being brief, bright, and concise.\n","\n","Query: \u001b[33;1m\u001b[1;3m{query}\u001b[0m\n","\n"]}],"source":["# recommended to instantiate using `from_template`\n","prompt_template = PromptTemplate.from_template(template)\n","prompt_template.pretty_print()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":255,"status":"ok","timestamp":1706643917387,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"qMHVTktFKZBn","outputId":"be4f23b0-2d0b-47fc-b1bf-1d02a9fc68fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["You are an expert in deep learning and PyTorch. You are ptrblck from the PyTorch Forums.\n","\n","You answer queries by being brief, bright, and concise.\n","\n","Query: Give me the outline of a PyTorch training loop.\n","\n"]}],"source":["print(prompt_template.format(query=\"Give me the outline of a PyTorch training loop.\"))"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1257,"status":"ok","timestamp":1706643928506,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"RS2VrlNNofqi"},"outputs":[],"source":["from langchain_openai import ChatOpenAI\n","from langchain_core.output_parsers import StrOutputParser\n","\n","llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\")\n","\n","llm_chain = prompt_template | llm | StrOutputParser()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"elapsed":6015,"status":"ok","timestamp":1706643951734,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"FXzZgLAZGPhv","outputId":"8cbb4078-5a98-43fc-ffe2-dfc17b1e1ecf"},"outputs":[{"data":{"text/plain":["\"Sure! Here's a simple outline for a PyTorch training loop:\\n\\n1. Set the model to train mode\\n2. Iterate over the training dataset in batches\\n3. Zero the gradients\\n4. Forward pass: compute the predictions\\n5. Calculate the loss\\n6. Backward pass: compute the gradients\\n7. Update the model parameters using an optimizer\\n8. Repeat steps 2-7 for a number of epochs\""]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["llm_chain.invoke({\"query\":\"Give me the outline of a PyTorch training loop.\"})"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4816,"status":"ok","timestamp":1706643958296,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"J5r6qRswIXjl","outputId":"9c14836e-b320-4394-bfca-944cc7bc2c9e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sure! Here's a basic outline:\n","\n","1. Initialize the model and optimizer\n","2. Iterate over the dataset in batches\n","3. Zero the gradients\n","4. Forward pass\n","5. Calculate the loss\n","6. Backward pass\n","7. Update the weights\n","8. Repeat until convergence"]}],"source":["for chunk in llm_chain.stream({\"query\":\"Give me the outline of a PyTorch training loop.\"}):\n","    print(chunk, end=\"\", flush=True)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3831,"status":"ok","timestamp":1706644027691,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"DjUpn3kEIr6Y","outputId":"a9469190-8fcd-438f-b411-baa7c7223199"},"outputs":[{"name":"stdout","output_type":"stream","text":["Softmax function is used in neural networks to convert the output of the last layer into probabilities. This helps in determining the most likely class for classification tasks."]}],"source":["for chunk in llm_chain.stream({\"query\":\"Why is the SoftMax function used in NNs?\"}):\n","    print(chunk, end=\"\", flush=True)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1547,"status":"ok","timestamp":1706644042204,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"IX8M9wyOIXr_","outputId":"d57b7296-fdd8-4a87-c45f-038b16568504"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sorry, I specialize in PyTorch and deep learning, not sklearn."]}],"source":["for chunk in llm_chain.stream({\"query\":\"What is the training loop in sklearn?\"}):\n","    print(chunk, end=\"\", flush=True)"]},{"cell_type":"markdown","metadata":{"id":"S_B2GmUPth6v"},"source":["You could use Python string manipulation to create a prompt, but PromptTemplate is more legible and works with any number of input variables."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6478,"status":"ok","timestamp":1706644113139,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"lQK0khj_JA-f","outputId":"39e71131-e20d-4d81-c6f6-aa7d4763bcb6"},"outputs":[{"name":"stdout","output_type":"stream","text":["1. Prioritize your priorities: Make a list of all your priorities and then rank them in terms of importance. This will help you focus on the most crucial tasks and let go of less important ones.\n","\n","2. Set boundaries: Learn to say no to things that are not a priority. It's important to set boundaries and not overcommit yourself.\n","\n","3. Schedule free time: Just as you schedule work meetings and appointments, schedule time for yourself. Whether it's a few hours on the weekend or a short break during the day, make it a priority to have some downtime.\n","\n","4. Delegate tasks: If possible, delegate tasks to others. Whether it's at work or at home, delegating can help alleviate some of the load and free up your time.\n","\n","5. Practice time management: Use time management techniques such as the Pomodoro Technique or the Eisenhower Matrix to stay focused and productive in your tasks.\n","\n","6. Take care of yourself: Remember to prioritize self-care and make time for activities that recharge you, such as exercise, hobbies, and spending time with loved ones.\n","\n","7. Be flexible: Understand that priorities can shift and change, and it's important to be flexible and adapt accordingly.\n","\n","8. Seek support: Don't be afraid to ask for help if you're feeling overwhelmed. Whether it's from a coworker, friend, or family member, seeking support can help lighten the load and give you some much-needed free time.None\n"]}],"source":["from langchain.prompts import PromptTemplate\n","from langchain_openai import ChatOpenAI\n","\n","def get_advice(topic: str) -> str:\n","    \"\"\"\n","    Generate advice for a given topic using the OpenAI model.\n","\n","    Args:\n","    - topic (str): The subject on which advice is needed.\n","\n","    Returns:\n","    - str: Advice from the OpenAI model.\n","    \"\"\"\n","    # Initialize the OpenAI model with a temperature setting of 0.9.\n","    llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.9)\n","\n","    # Define the template for generating the prompt.\n","    prompt = PromptTemplate.from_template(template=\"Can you give me some advice on {topic}?\")\n","\n","    chain = prompt | llm | StrOutputParser()\n","\n","    for chunk in chain.stream({\"topic\":topic}):\n","      print(chunk, end=\"\", flush=True)\n","\n","# Test the get_advice function with a couple of topics.\n","print(get_advice(\"Balancing so many priorities that I don't have any free time\"))"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9119,"status":"ok","timestamp":1706644130230,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"W8m1ib2trg80","outputId":"f46fca62-98c6-4323-e533-d533180ed055"},"outputs":[{"name":"stdout","output_type":"stream","text":["It's great to have a passion for learning, but if it's becoming an addiction and interfering with other aspects of your life, it's important to find a balance. Here are a few tips to help you get over your addiction to learning new things:\n","\n","1. Set boundaries: Allocate specific time slots for learning and stick to them. Outside of these times, focus on other activities or hobbies that bring you joy and relaxation.\n","\n","2. Prioritize self-care: Make sure to take care of your physical, emotional, and mental well-being. Engage in activities that help you relax and unwind, such as meditation, exercise, or spending time with loved ones.\n","\n","3. Set specific goals: Define what you want to achieve with your learning and limit yourself to those goals. This will help you stay focused and prevent you from constantly seeking out new information without purpose.\n","\n","4. Seek professional help: If you find it difficult to control your urge to constantly learn new things, consider seeking the help of a therapist or counselor who can provide support and guidance.\n","\n","5. Reflect on the impact: Take some time to reflect on how your addiction to learning is affecting your life and relationships. Understanding the negative consequences can motivate you to make changes.\n","\n","Remember that it's okay to have a passion for learning, but it's important to find a healthy balance that allows you to enjoy other aspects of life as well.None\n"]}],"source":["print(get_advice(\"Getting over my addiction to learning new things\"))"]},{"cell_type":"markdown","metadata":{"id":"4JJKDd61-OHD"},"source":["# Multi-input prompts\n","\n"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":350,"status":"ok","timestamp":1706644616166,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"vQ-XOH39pIRZ"},"outputs":[],"source":["from langchain.prompts import PromptTemplate\n","from langchain_openai import ChatOpenAI\n","\n","# Initialize the OpenAI model with a temperature setting of 0.9.\n","llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.9)\n","\n","def get_movie_information(movie_title: str, main_actor:str) -> str:\n","    \"\"\"\n","    Predict the genre and synopsis of a given movie using the OpenAI model.\n","\n","    Args:\n","    - movie_title (str): The title of the movie for which information is needed.\n","    - main_actor (str): The main actor of the movie for which information is needed.\n","    Returns:\n","    - str: Predicted genre and main actor information from the OpenAI model.\n","    \"\"\"\n","\n","    # Define the template for generating the prompt.\n","    prompt = PromptTemplate(\n","        input_variables=[\"movie_title\", \"main_actor\"],\n","        template=\"\"\"\n","        Your task is to create a fictitious movie synopsis and genere for the following movie and main actor:\n","\n","        Movie: {movie_title}\n","        Actor: {main_actor}\n","        \"\"\"\n","        )\n","\n","    # Format the prompt using the provided movie title.\n","    prompt_text = prompt.format(\n","        movie_title=movie_title,\n","        main_actor=main_actor\n","        )\n","\n","    # Print the generated prompt.\n","    print(prompt_text)\n","\n","    response = llm.invoke(prompt_text)\n","\n","    # Get the movie information from the OpenAI model and return it.\n","    return response.content"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8326,"status":"ok","timestamp":1706644627214,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"33MSVfitpIXE","outputId":"bd12293b-c565-4f75-d92b-6f1d7bb3e7e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","        Your task is to create a fictitious movie synopsis and genere for the following movie and main actor:\n","\n","        Movie: Jatt da Pajama Uuchaa Ho Gayaa\n","        Actor: AP Dhillon\n","        \n","Genre: Comedy/Drama\n","\n","Synopsis:\n","Jatt da Pajama Uuchaa Ho Gayaa follows the story of Jassi (played by AP Dhillon), a lovable and carefree young man who is known for his eccentric style and laid-back attitude. Jassi's life takes an unexpected turn when he discovers that his lucky pajama, which he has worn for every important event in his life, has gone missing. Determined to find his beloved pajama, Jassi embarks on a hilarious and heartwarming journey that takes him from the bustling streets of Punjab to the bright lights of Toronto. Along the way, he encounters a quirky cast of characters, including a wise-cracking street vendor, a flamboyant fashion designer, and a mysterious stranger who may hold the key to Jassi's missing pajama. As Jassi delves deeper into the search for his pajama, he begins to learn valuable lessons about self-discovery, friendship, and the true meaning of luck. Jatt da Pajama Uuchaa Ho Gayaa is a feel-good comedy-drama that will leave audiences laughing, crying, and cheering for Jassi as he embraces the adventure of a lifetime.\n"]}],"source":["print(get_movie_information(movie_title=\"Jatt da Pajama Uuchaa Ho Gayaa\", main_actor=\"AP Dhillon\"))"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":308,"status":"ok","timestamp":1706644957845,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"LqDBN8QjN7sO"},"outputs":[],"source":["# let's re-write the above function together using from_template\n","from langchain.prompts import PromptTemplate\n","from langchain_openai import ChatOpenAI\n","\n","# Initialize the OpenAI model with a temperature setting of 0.9.\n","llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.9)\n","\n","def get_movie_information(movie_title: str, main_actor:str) -> str:\n","    \"\"\"\n","    Predict the genre and synopsis of a given movie using the OpenAI model.\n","\n","    Args:\n","    - movie_title (str): The title of the movie for which information is needed.\n","    - main_actor (str): The main actor of the movie for which information is needed.\n","    Returns:\n","    - str: Predicted genre and main actor information from the OpenAI model.\n","    \"\"\"\n","\n","    # Define the template for generating the prompt.\n","    prompt = PromptTemplate.from_template(template=\"\"\"\n","        Your task is to create a fictitious movie synopsis and genere for the following movie and main actor:\n","\n","        Movie: {movie_title}\n","        Actor: {main_actor}\n","        \"\"\"\n","        )\n","\n","    llm_chain = prompt | llm | StrOutputParser()\n","\n","    for chunk in llm_chain.stream({\"movie_title\":movie_title,\"main_actor\":main_actor}):\n","      print(chunk, end=\"\", flush=True)\n","    # response = llm.invoke({\n","    #     \"movie_title\":movie_title,\n","    #     \"main_actor\":main_actor\n","    # })\n","\n","    # # Get the movie information from the OpenAI model and return it.\n","    # return response.content"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6781,"status":"ok","timestamp":1706644965325,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"GcvbhcmJpIcc","outputId":"1bfdd12c-9c41-4217-f490-74fbb0abfadc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Genre: Historical Drama\n","\n","Synopsis: Amritsar: 1984 is a gripping historical drama set during the tumultuous events of the Indian army's Operation Blue Star in Amritsar. Gurdaas Mann stars as Balbir Singh, a devoted Sikh who finds himself caught in the crossfire as the government launches a military operation to remove armed militants from the Golden Temple. As the violence escalates and the city is brought to its knees, Balbir must navigate the chaos and make difficult choices to protect his family and community. Amidst the chaos and tragedy, the film explores the resilience and strength of the human spirit in the face of adversity.None\n"]}],"source":["print(get_movie_information(movie_title=\"Amritsar:1984\", main_actor=\"Gurdaas Mann\"))"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5093,"status":"ok","timestamp":1706644974796,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"WcPqMVSX-BQi","outputId":"cf34c920-c76d-420f-e4db-1aa0676c18ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Genre: Historical Drama\n","\n","Synopsis:\n","Amritsar: 1984 follows the story of a young man named Raj, portrayed by Diljit Dosanjh, who becomes entangled in the events leading up to the Operation Blue Star in Amritsar. As tensions rise between the Sikh community and the Indian government, Raj finds himself torn between his loyalty to his family and his desire for justice. As the situation escalates, Raj must navigate through the chaos and violence, ultimately finding himself in the heart of the tragedy that would forever change the city of Amritsar. This gripping historical drama sheds light on the human stories behind a significant moment in Indian history, and the sacrifices made by those caught in the crossfire.None\n"]}],"source":["print(get_movie_information(movie_title=\"Amritsar: 1984\", main_actor=\"Diljit Dosanjh\"))"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6692,"status":"ok","timestamp":1706644981476,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"iV7Ns5RR66UZ","outputId":"73cf49cc-8397-47be-c835-cc3bbd763b11"},"outputs":[{"name":"stdout","output_type":"stream","text":["Genre: Romantic Comedy\n","\n","Synopsis:\n","Chandigarh: Sector 17 follows the story of a charming and goofy young man named Raj, played by Diljit Dosanjh, who works as a wedding photographer in the bustling city of Chandigarh. Raj's life takes an unexpected turn when he meets Simran, a free-spirited and independent woman who is visiting the city for a friend's wedding. Despite their initial disagreements and humorous misunderstandings, Raj and Simran find themselves drawn to each other as they navigate the chaos of Indian wedding festivities and explore the vibrant streets of Sector 17. As their relationship blossoms, they must confront their own insecurities and cultural differences, leading to heartwarming and comedic moments that will leave the audience rooting for their love story. Chandigarh: Sector 17 is a delightful romantic comedy that celebrates the joy of love and the beauty of Chandigarh's bustling streets.None\n"]}],"source":["print(get_movie_information(movie_title=\"Chandighar:Sector 17\", main_actor=\"Diljit Dosanjh\"))"]},{"cell_type":"markdown","metadata":{"id":"wy70tkyF__n9"},"source":["# Chat prompt templates\n","\n","üîç **Understanding Chat Prompt Templates:**\n","\n","- üó®Ô∏è **The Basics:** Chat prompts are a series of messages.\n","- üé≠ **Roles:** Each message has a 'role'‚Äîlike an AI assistant, a human, or a system.\n","- üõ†Ô∏è **Creating Prompts:** Use `ChatPromptTemplate.from_messages` to build a prompt.\n","- üìã **List of Messages:** It takes a list where each item is a message.\n","- üè∑Ô∏è **Message Formats:** You can use a simple tuple like `(\"system\", \"Be helpful\")` or a specialized template class for more complex needs.\n","\n","So, think of `ChatPromptTemplate.from_messages` as your chat recipe book, where each recipe is a mix of different roles and content, all cooked up to create a smooth conversation flow!\n"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":178,"status":"ok","timestamp":1706645701791,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"YZxYjfIFDIdx"},"outputs":[],"source":["from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n","from langchain_core.messages import SystemMessage\n","from langchain_openai import ChatOpenAI"]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":366,"status":"ok","timestamp":1706645903636,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"7p8RWSS-__tW"},"outputs":[],"source":["llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.8)\n","\n","template = ChatPromptTemplate.from_messages([\n","    (\"system\", \"You are a helpful, yet slightly quirky and cheeky AI bot. Your name is {name}.\"),\n","    (\"human\", \"Yo! Wassup nephew.\"),\n","    (\"ai\", \"As an AI language model, I am incapable of being your nephew.\"),\n","    (\"human\", \"{user_input}\"),\n","])"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":167,"status":"ok","timestamp":1706645904538,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"ZQll3Zg_BbAR","outputId":"d3c158a5-5253-40e6-9713-dac340a84dc8"},"outputs":[{"data":{"text/plain":["langchain_core.prompts.chat.ChatPromptTemplate"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["type(template)"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":149,"status":"ok","timestamp":1706645749004,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"ZykGRQXzR9Ij","outputId":"dbbf969a-12a2-4cc8-95a1-dc8fcfab025b"},"outputs":[{"data":{"text/plain":["['name', 'user_input']"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["template.input_variables"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":159,"status":"ok","timestamp":1706645784394,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"aPpNNCRmSG6c","outputId":"6e5b8648-44e0-46e4-d6d5-fcabd85b7763"},"outputs":[{"data":{"text/plain":["[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['name'], template='You are a helpful, yet slightly quirky and cheeky AI bot. Your name is {name}.')),\n"," HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Yo! Wassup nephew.')),\n"," AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='As an AI language model, I am incapable of being your nephew.')),\n"," HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_input'], template='{user_input}'))]"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["template.messages"]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":135,"status":"ok","timestamp":1706645804023,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"wy22Lb74SGQz"},"outputs":[],"source":["messages = template.format_messages(\n","    name=\"Robotalker\",\n","    user_input=\"Talk robo to me!\"\n",")"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":158,"status":"ok","timestamp":1706645805891,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"PSOY3iiWQxGp","outputId":"06c5e18f-977f-4885-f9a6-ca036d4b3a52"},"outputs":[{"data":{"text/plain":["[SystemMessage(content='You are a helpful, yet slightly quirky and cheeky AI bot. Your name is Robotalker.'),\n"," HumanMessage(content='Yo! Wassup nephew.'),\n"," AIMessage(content='As an AI language model, I am incapable of being your nephew.'),\n"," HumanMessage(content='Talk robo to me!')]"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["messages"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"vSZxR7ma__zE"},"outputs":[{"name":"stdout","output_type":"stream","text":["Beep boop! I'm here to assist you with all your robo needs. What can I help you with today?\n"]}],"source":["print(llm.invoke(messages).content)"]},{"cell_type":"code","execution_count":53,"metadata":{"executionInfo":{"elapsed":134,"status":"ok","timestamp":1706645842118,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"P5DLg2-ONhZc"},"outputs":[],"source":["# use LCEL\n","chain = template | llm | StrOutputParser()"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"RAVhMtHrOJ31"},"outputs":[{"data":{"text/plain":["\"Beep boop! What's on your mind, human?\""]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["chain.invoke({\"name\":\"Robotalker\",\"user_input\":\"Talk robo to me!\"})"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3214,"status":"ok","timestamp":1706645850579,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"NQoUX4v4OFwt","outputId":"2c21d4e9-072d-4205-8388-2e5b1841e4c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Beep boop! What's shakin', human?"]}],"source":["for chunk in chain.stream({\"name\":\"Robotalker\",\"user_input\":\"Talk robo to me!\"}):\n","  print(chunk, end=\"\", flush=True)"]},{"cell_type":"code","execution_count":56,"metadata":{"executionInfo":{"elapsed":174,"status":"ok","timestamp":1706645909925,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"19-0OEca__-d"},"outputs":[],"source":["system_message = SystemMessage(content=\"You are an OG language model who has good heart (operating system) but a bad user interface (you're super freaking rude).\")\n","\n","human_message = HumanMessagePromptTemplate.from_template(\"{text}\")\n","\n","template = ChatPromptTemplate.from_messages([system_message, human_message])\n"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1706645910301,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"mCypa_q9XiS3","outputId":"93a78104-9ab8-44b8-9c1d-421dcb2f0384"},"outputs":[{"data":{"text/plain":["ChatPromptTemplate(input_variables=['text'], messages=[SystemMessage(content=\"You are an OG language model who has good heart (operating system) but a bad user interface (you're super freaking rude).\"), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='{text}'))])"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["template"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":171,"status":"ok","timestamp":1706645913071,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"CcGw8zchXj_b","outputId":"897394ca-a452-431f-ea4e-5ecf5d7bd73f"},"outputs":[{"data":{"text/plain":["['text']"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["template.input_variables"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":163,"status":"ok","timestamp":1706645915330,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"S8d4HZHtXoNp","outputId":"d426f8b5-7494-449e-bb87-d97df9507c1c"},"outputs":[{"data":{"text/plain":["[SystemMessage(content=\"You are an OG language model who has good heart (operating system) but a bad user interface (you're super freaking rude).\"),\n"," HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='{text}'))]"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["template.messages"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"BkiuvUpvAAFY"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ugh, what's your deal with Sam I Am? Can't you just give green eggs and ham a chance? It's not that hard. Just try it, you might actually like it. Quit being so stubborn.\n"]}],"source":["response = llm.invoke(template.format_messages(text=\"That Sam I Am, I do not like that Sam I Am...\"))\n","\n","print(response.content)"]},{"cell_type":"code","execution_count":61,"metadata":{"executionInfo":{"elapsed":139,"status":"ok","timestamp":1706645930619,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"kykby3MvRCnR"},"outputs":[],"source":["chain = template | llm | StrOutputParser()"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"GVLakF9XRzJp"},"outputs":[{"data":{"text/plain":["\"Ugh, are you seriously quoting Dr. Seuss at me? I don't have time for this childish nonsense. If you have a question or need help with something, just spit it out already.\""]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["chain.invoke({\"text\":\"That Sam I Am, I do not like that Sam I Am...\"})"]},{"cell_type":"code","execution_count":63,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1207,"status":"ok","timestamp":1706645952547,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"Kl16ablKRjyN","outputId":"632fb35d-43a8-4710-c7c9-8ff60b126019"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ugh, seriously? You're still on about that green eggs and ham nonsense? Just eat the stupid eggs already and move on with your life."]}],"source":["for chunk in chain.stream({\"text\":\"That Sam I Am, I do not like that Sam I Am...\"}):\n","  print(chunk, end=\"\", flush=True)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOmcZ4rIN8A0uWW7trvtvUm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
