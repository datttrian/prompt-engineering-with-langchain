{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":31084,"status":"ok","timestamp":1706678778257,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"BZSHoJJhFP4_"},"outputs":[],"source":["%%capture\n","!pip install langchain==0.1.4 openai==1.10.0 langchain-openai datasets faiss-gpu sentence_transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6611,"status":"ok","timestamp":1706679000028,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"ROv0ygONORNx","outputId":"dd015dc1-952d-42d5-8783-9770243f0327"},"outputs":[],"source":["import os\n","import getpass\n","\n","os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter Your OpenAI API Key:\")"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":316,"status":"ok","timestamp":1706679002217,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"sq7OvPt1_2XX"},"outputs":[],"source":["from langchain.globals import set_verbose\n","\n","set_verbose(True)"]},{"cell_type":"markdown","metadata":{"id":"zEAWUvegOw27"},"source":["#ğŸ”— **Origins of CoT Prompting**\n","\n","- CoT was introduced by Wei et al. in their 2022 paper, [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://browse.arxiv.org/pdf/2201.11903.pdf).\n","\n","- It's a response to the need for better reasoning in large language models.\n","\n","ğŸ’¡ **What is CoT Prompting?**\n","- CoT stands for Chain of Thought Prompting.\n","\n","- It's about guiding language models through a step-by-step reasoning process.\n","\n","- The model shows its reasoning, forming a \"chain\" of thoughts, rather than just giving an answer.\n","\n","- Mimics human-like thought processes for complex tasks.\n","\n","\n","### ğŸ“ **Standard vs. CoT Prompting Example**\n","\n","<figure>\n","  <img src=\"https://deepgram.com/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F96965%2F1696369825-cot-example.png&w=3840&q=75\" alt=\"Image Description\" style=\"width:100%\">\n","  <figcaption>Examples of âŸ¨input, chain of thought, outputâŸ© triples for arithmetic, commonsense, and symbolic reasoning benchmarks. Chains of thought are highlighted.</figcaption>\n","  <a href=\"https://deepgram.com/_next/image?url=https%3A%2F%2Fwww.datocms-assets.com%2F96965%2F1696369825-cot-example.png&w=3840&q=75\">Image Source</a>\n","</figure>\n","\n","- Standard: Direct answer with no reasoning (e.g., \"11\").\n","\n","- CoT: Detailed reasoning steps (e.g., \"Roger started with 5, added 6 from 2 cans, so 5 + 6 = 11\").\n","\n","### ğŸš€ **Usage of CoT Prompting**\n","\n","1. **Enhanced Reasoning**: Breaks down complex problems into simpler steps.\n","\n","2. **Combination with Few-Shot Prompting**: Uses examples to guide model responses, great for complex tasks.\n","\n","3. **Interpretability**: Offers a clear view of the model's thought process.\n","\n","4. **Applications**: Useful in arithmetic, commonsense reasoning, and symbolic tasks.\n","\n","### âœ¨ **Impact of CoT Prompting**\n","\n","- Improves accuracy and insightfulness in responses.\n","\n","- Focuses on reasoning and interpretability, especially in complex scenarios."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Collecting datasets\n","  Using cached datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n","Collecting filelock (from datasets)\n","  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n","Requirement already satisfied: numpy>=1.17 in /home/vscode/.local/lib/python3.12/site-packages (from datasets) (1.26.4)\n","Collecting pyarrow>=12.0.0 (from datasets)\n","  Downloading pyarrow-16.1.0-cp312-cp312-manylinux_2_28_aarch64.whl.metadata (3.0 kB)\n","Collecting pyarrow-hotfix (from datasets)\n","  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Collecting pandas (from datasets)\n","  Downloading pandas-2.2.2-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (19 kB)\n","Requirement already satisfied: requests>=2.19.0 in /home/vscode/.local/lib/python3.12/site-packages (from datasets) (2.32.2)\n","Requirement already satisfied: tqdm>=4.62.1 in /home/vscode/.local/lib/python3.12/site-packages (from datasets) (4.66.4)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.3.1,>=2023.1.0 (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets)\n","  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n","Requirement already satisfied: aiohttp in /home/vscode/.local/lib/python3.12/site-packages (from datasets) (3.9.5)\n","Collecting huggingface-hub>=0.21.2 (from datasets)\n","  Downloading huggingface_hub-0.23.1-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: packaging in /home/vscode/.local/lib/python3.12/site-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /home/vscode/.local/lib/python3.12/site-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /home/vscode/.local/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /home/vscode/.local/lib/python3.12/site-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /home/vscode/.local/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /home/vscode/.local/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /home/vscode/.local/lib/python3.12/site-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/vscode/.local/lib/python3.12/site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/vscode/.local/lib/python3.12/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /home/vscode/.local/lib/python3.12/site-packages (from requests>=2.19.0->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vscode/.local/lib/python3.12/site-packages (from requests>=2.19.0->datasets) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/vscode/.local/lib/python3.12/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /home/vscode/.local/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n","Collecting pytz>=2020.1 (from pandas->datasets)\n","  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n","Collecting tzdata>=2022.7 (from pandas->datasets)\n","  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading huggingface_hub-0.23.1-py3-none-any.whl (401 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m401.3/401.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyarrow-16.1.0-cp312-cp312-manylinux_2_28_aarch64.whl (38.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading filelock-3.14.0-py3-none-any.whl (12 kB)\n","Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m146.7/146.7 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pandas-2.2.2-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (15.2 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n","Downloading xxhash-3.4.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (220 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m220.9/220.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pytz, xxhash, tzdata, pyarrow-hotfix, pyarrow, fsspec, filelock, dill, pandas, multiprocess, huggingface-hub, datasets\n","Successfully installed datasets-2.19.1 dill-0.3.8 filelock-3.14.0 fsspec-2024.3.1 huggingface-hub-0.23.1 multiprocess-0.70.16 pandas-2.2.2 pyarrow-16.1.0 pyarrow-hotfix-0.6 pytz-2024.1 tzdata-2024.1 xxhash-3.4.1\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install datasets"]},{"cell_type":"markdown","metadata":{"id":"8ho8Ee15qQGw"},"source":["The code below downloads an dataset which has over [1.8 million Chain of Thought examples](https://huggingface.co/datasets/kaist-ai/CoT-Collection)."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"fCE2VgOPO_L4"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/vscode/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","Downloading builder script: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.07k/4.07k [00:00<00:00, 11.7MB/s]\n","Downloading readme: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.68k/2.68k [00:00<00:00, 18.6MB/s]\n","Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.36G/2.36G [02:35<00:00, 15.2MB/s]\n","Generating train split: 1837928 examples [00:50, 36176.12 examples/s]\n"]}],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"kaist-ai/CoT-Collection\", split=\"train\", trust_remote_code=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":672,"status":"ok","timestamp":1706678952642,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"Z0DY6By96mqc","outputId":"91050859-80ad-4f88-ce64-01d72dc78ea7"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source</th>\n","      <th>target</th>\n","      <th>rationale</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Question: What about Neptune did NASA propose ...</td>\n","      <td>no</td>\n","      <td>The proposed mission to Neptune is not mention...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Choose your reply from the options at the end....</td>\n","      <td>yes</td>\n","      <td>The passage talks about the Tucson-Pima County...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>You are given an original reference as well as...</td>\n","      <td>1</td>\n","      <td>The system generated reference is grammaticall...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Is the premise \"A person on a beach in a green...</td>\n","      <td>yes</td>\n","      <td>The premise describes a situation where there ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Pick the option in line with common sense to a...</td>\n","      <td>C</td>\n","      <td>The rationale is: \"C, expected because it was ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              source target  \\\n","0  Question: What about Neptune did NASA propose ...     no   \n","1  Choose your reply from the options at the end....    yes   \n","2  You are given an original reference as well as...      1   \n","3  Is the premise \"A person on a beach in a green...    yes   \n","4  Pick the option in line with common sense to a...      C   \n","\n","                                           rationale  \n","0  The proposed mission to Neptune is not mention...  \n","1  The passage talks about the Tucson-Pima County...  \n","2  The system generated reference is grammaticall...  \n","3  The premise describes a situation where there ...  \n","4  The rationale is: \"C, expected because it was ...  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":[" dataset = dataset.remove_columns(['task', 'type'])\n","\n"," dataset = dataset.shuffle(seed=42)\n","\n"," dataset = dataset.select(range(10_000))\n","\n"," dataset = dataset.to_pandas()\n","\n"," dataset.head()"]},{"cell_type":"markdown","metadata":{"id":"ATBYAzaXqfy1"},"source":["We'll sample just 10,000 of these Chain of Thought examples and save them as a list of dictionaries."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":311,"status":"ok","timestamp":1706678985658,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"duffkBFV69MV"},"outputs":[],"source":["selected_examples = dataset.to_dict(orient='records')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1706678986795,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"kIFKE7Pd9YQj","outputId":"0b37eea0-e9dc-41b9-f583-02296169cc49"},"outputs":[{"data":{"text/plain":["{'source': 'Question: What about Neptune did NASA propose in 2003 in their \"Vision Missions Studies\"?\\n\\nIs However, there have been a couple of discussions to launch Neptune missions sooner. a good answer to this question?\\n\\nOPTIONS:\\n- yes\\n- no',\n"," 'target': 'no',\n"," 'rationale': 'The proposed mission to Neptune is not mentioned. The only mention of the planet in this excerpt is a note that there have been proposals for such missions, but they are very distant and probably will never happen.'}"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["selected_examples[0]"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Collecting sentence-transformers\n","  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n","Collecting transformers<5.0.0,>=4.34.0 (from sentence-transformers)\n","  Downloading transformers-4.41.0-py3-none-any.whl.metadata (43 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /home/vscode/.local/lib/python3.12/site-packages (from sentence-transformers) (4.66.4)\n","Collecting torch>=1.11.0 (from sentence-transformers)\n","  Downloading torch-2.3.0-cp312-cp312-manylinux2014_aarch64.whl.metadata (26 kB)\n","Requirement already satisfied: numpy in /home/vscode/.local/lib/python3.12/site-packages (from sentence-transformers) (1.26.4)\n","Collecting scikit-learn (from sentence-transformers)\n","  Downloading scikit_learn-1.5.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (11 kB)\n","Collecting scipy (from sentence-transformers)\n","  Downloading scipy-1.13.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (113 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m113.1/113.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub>=0.15.1 in /home/vscode/.local/lib/python3.12/site-packages (from sentence-transformers) (0.23.1)\n","Collecting Pillow (from sentence-transformers)\n","  Downloading pillow-10.3.0-cp312-cp312-manylinux_2_28_aarch64.whl.metadata (9.2 kB)\n","Requirement already satisfied: filelock in /home/vscode/.local/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.14.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /home/vscode/.local/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\n","Requirement already satisfied: packaging>=20.9 in /home/vscode/.local/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /home/vscode/.local/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n","Requirement already satisfied: requests in /home/vscode/.local/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/vscode/.local/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n","Collecting sympy (from torch>=1.11.0->sentence-transformers)\n","  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n","Collecting networkx (from torch>=1.11.0->sentence-transformers)\n","  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n","Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n","  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: regex!=2019.12.17 in /home/vscode/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n","Collecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n","  Downloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.7 kB)\n","Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.34.0->sentence-transformers)\n","  Downloading safetensors-0.4.3-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (3.8 kB)\n","Requirement already satisfied: joblib>=1.2.0 in /home/vscode/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n","Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n","  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n","Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n","  Downloading MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (3.0 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/vscode/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /home/vscode/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vscode/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/vscode/.local/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n","Collecting mpmath>=0.19 (from sympy->torch>=1.11.0->sentence-transformers)\n","  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n","Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.3.0-cp312-cp312-manylinux2014_aarch64.whl (88.4 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.4/88.4 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading transformers-4.41.0-py3-none-any.whl (9.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading pillow-10.3.0-cp312-cp312-manylinux_2_28_aarch64.whl (4.3 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading scikit_learn-1.5.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (12.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading scipy-1.13.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (33.4 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m33.4/33.4 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading safetensors-0.4.3-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.2 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n","Downloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (3.6 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading networkx-3.3-py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading sympy-1.12-py3-none-any.whl (5.7 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (29 kB)\n","Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: mpmath, threadpoolctl, sympy, scipy, safetensors, Pillow, networkx, MarkupSafe, scikit-learn, jinja2, torch, tokenizers, transformers, sentence-transformers\n","Successfully installed MarkupSafe-2.1.5 Pillow-10.3.0 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 safetensors-0.4.3 scikit-learn-1.5.0 scipy-1.13.0 sentence-transformers-2.7.0 sympy-1.12 threadpoolctl-3.5.0 tokenizers-0.19.1 torch-2.3.0 transformers-4.41.0\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install sentence-transformers"]},{"cell_type":"markdown","metadata":{"id":"ctCFgLemqll9"},"source":["For this example we'll use an open source embedding model from HuggingFace so we don't accumulate a huge bill for OpenAI"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":3834,"status":"ok","timestamp":1706679095210,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"qmyv-uT-EmyS"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/vscode/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"ename":"AssertionError","evalue":"Torch not compiled with CUDA enabled","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBAAI/bge-base-en-v1.5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m encode_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalize_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m} \u001b[38;5;66;03m# set True to compute cosine similarity\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceBgeEmbeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_kwargs\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.12/site-packages/langchain_community/embeddings/huggingface.py:236\u001b[0m, in \u001b[0;36mHuggingFaceBgeEmbeddings.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import sentence_transformers python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install sentence_transformers`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    234\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43msentence_transformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-zh\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_instruction \u001b[38;5;241m=\u001b[39m DEFAULT_QUERY_BGE_INSTRUCTION_ZH\n","File \u001b[0;32m~/.local/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:221\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, cache_folder, trust_remote_code, revision, token, use_auth_token, truncate_dim)\u001b[0m\n\u001b[1;32m    218\u001b[0m     device \u001b[38;5;241m=\u001b[39m get_device_name()\n\u001b[1;32m    219\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse pytorch device_name: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(device))\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_hpu_graph_enabled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts:\n","File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","    \u001b[0;31m[... skipping similar frames: Module._apply at line 779 (1 times)]\u001b[0m\n","File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1154\u001b[0m             device,\n\u001b[1;32m   1155\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1156\u001b[0m             non_blocking,\n\u001b[1;32m   1157\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1158\u001b[0m         )\n\u001b[0;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/cuda/__init__.py:284\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m     )\n","\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"]}],"source":["from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n","\n","model_name = \"BAAI/bge-base-en-v1.5\"\n","\n","encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n","\n","embeddings = HuggingFaceBgeEmbeddings(\n","    model_name=model_name,\n","    model_kwargs={'device': 'cuda'},\n","    encode_kwargs=encode_kwargs\n",")"]},{"cell_type":"markdown","metadata":{"id":"aU69WA8pq0wb"},"source":["To set up a Chain of Thought prompt you will use a `FewShotPromptTemplate` as well as an example selector.\n","\n","In this example you'll use `MaxMarginalRelevanceExampleSelector`, but you can use any of the example selectors you learned about before."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":351,"status":"ok","timestamp":1706679404593,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"6YLFBPqMFId7"},"outputs":[],"source":["from langchain.prompts.example_selector import MaxMarginalRelevanceExampleSelector\n","\n","from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n","\n","from langchain_community.vectorstores import FAISS"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":347,"status":"ok","timestamp":1706679442334,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"zYhYHn7NF4n_"},"outputs":[],"source":["prefix = \"Consider the following as examples of how to reason:\"\n","\n","examples_template = \"\"\"Query: {source}\n","\n","Rationale: {rationale}\n","\n","Response: {target}\n","\"\"\"\n","\n","suffix = \"\"\"Using a similar reasoning approach, answer the users question which is delimited by triple backticks.\n","\n","User question: ```{input}```\n","\n","Take a deep breath, break down the user's query step-by-step, and provide a clear chain of thought in your response.\"\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":364,"status":"ok","timestamp":1706679453143,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"nXD2hFzNH9hL"},"outputs":[],"source":["examples_prompt = PromptTemplate(\n","    input_variables=[\"source\", \"rationale\", \"target\"],\n","    template=examples_template\n",")"]},{"cell_type":"markdown","metadata":{"id":"vXuPx89GtMLv"},"source":["There's a large number of examples to embed and add to the vector store. The below cell will take a few minutes to run. It took me ~3 minutes using the free T4 GPU provided on Google colab."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":186888,"status":"ok","timestamp":1706679667969,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"5SA1Tst3IO6J"},"outputs":[],"source":["example_selector = MaxMarginalRelevanceExampleSelector.from_examples(\n","    # The list of examples available to select from.\n","    selected_examples,\n","    # The embedding class used to produce embeddings which are used to measure semantic similarity.\n","    embeddings,\n","    # The VectorStore class that is used to store the embeddings and do a similarity search over.\n","    FAISS,\n","    # The number of examples to produce.\n","    k=7,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1706679667970,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"cuFE8t32IX7S"},"outputs":[],"source":["mmr_prompt = FewShotPromptTemplate(\n","    example_selector=example_selector,\n","    example_prompt=examples_prompt,\n","    prefix=prefix,\n","    suffix=suffix,\n","    input_variables=[\"input\"]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1706679667970,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"shEayc6UI0o1"},"outputs":[],"source":["query = \"\"\"Here's a short story: A lifter uses a barbell, but moves a jump rope\\\n","in a wider arc. The object likely to travel further is (A) the jump rope (B) the\\\n","barbell.\n","\n","What is the most sensical answer between \"a jump rope\" and \"a barbell\"?\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1706679667970,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"KfA-c4gvJM9Q","outputId":"300a3d1d-cae1-409c-acba-0f31100b73d9"},"outputs":[],"source":["print(mmr_prompt.format(input=query))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17532,"status":"ok","timestamp":1706679778282,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"KFw8vxigJTjW","outputId":"ce515fde-f96a-45b8-eb8f-0728907b3161"},"outputs":[],"source":["from langchain_openai import ChatOpenAI\n","from langchain_core.output_parsers import StrOutputParser\n","\n","llm = ChatOpenAI(model=\"gpt-4-0125-preview\", temperature=0.0)\n","\n","llm_chain = mmr_prompt | llm | StrOutputParser()\n","\n","for chunk in llm_chain.stream({\"input\":query}):\n","  print(chunk, end=\"\", flush=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":422,"status":"ok","timestamp":1706679798740,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"FftbmTl6LgQ-"},"outputs":[],"source":["query = \"\"\"\n","Given the fact that: Inhaling, or breathing in, increases the size of the chest, \\\n"," which decreases air pressure inside the lungs. Answer the question: If Mona is \\\n"," done with a race and her chest contracts, what happens to the amount of air \\\n"," pressure in her lungs increases or decreases?\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21125,"status":"ok","timestamp":1706679821198,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"},"user_tz":360},"id":"OZrMB0i0Lzif","outputId":"8f82828f-309a-4f05-acde-7a7500b1240e"},"outputs":[],"source":["for chunk in llm_chain.stream({\"input\":query}):\n","  print(chunk, end=\"\", flush=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xJFjvwxWCwvX"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNUpicQNfihPPdnwto66QtM","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
